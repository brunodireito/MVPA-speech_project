{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/brunomiguel/.local/lib/python3.8/site-packages/nilearn/datasets/__init__.py:87: FutureWarning: Fetchers from the nilearn.datasets module will be updated in version 0.9 to return python strings instead of bytes and Pandas dataframes instead of Numpy arrays.\n",
      "  warn(\"Fetchers from the nilearn.datasets module will be \"\n"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import nilearn\n",
    "from nilearn import plotting\n",
    "from nilearn import datasets\n",
    "from nilearn import image\n",
    "from nilearn.image import mean_img\n",
    "from nilearn import surface\n",
    "from nilearn.glm.contrasts import compute_contrast\n",
    "\n",
    "# Let us use a Nifti file that is shipped with nilearn\n",
    "from nilearn.datasets import MNI152_FILE_PATH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\bdireito\\Data\\BIDS\\sub-0001\\ses-001\n"
     ]
    }
   ],
   "source": [
    "# Set variables\n",
    "root_data=\"C:\\\\Users\\\\bdireito\\\\Data\\\\BIDS\"\n",
    "sub=\"sub-0001\"\n",
    "ses=\"ses-001\"\n",
    "\n",
    "file_sep=\"\\\\\"\n",
    "data_path=root_data + file_sep + sub + file_sep + ses\n",
    "\n",
    "print(data_path)\n",
    "\n",
    "root_project=\"C:\\\\Users\\\\bdireito\\\\Documents\\\\GitHub\\\\MVPA-speech_project\\\\\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Structural data.\n",
    "\n",
    "## Check registration using FSL BET (brain extraction) + FEAT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t1w_file_path=data_path + \"\\\\anat\\\\sub-0001_ses-001_run-01_T1w.nii.gz\"\n",
    "plotting.plot_img(t1w_file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t1w_brain_file_path=data_path + \"\\\\anat\\\\sub-0001_ses-001_run-01_T1w_brain.nii.gz\"\n",
    "\n",
    "plotting.plot_img(t1w_brain_file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t1w_prepro_file_path=data_path + \"\\\\run-1.feat\\\\reg\\\\highres2standard.nii.gz\"\n",
    "\n",
    "cut_coords=(0, 0, 0)\n",
    "plotting.plot_img(t1w_prepro_file_path, cut_coords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plotting.plot_img(datasets.MNI152_FILE_PATH, cut_coords)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Functional data.\n",
    "## Check preprocessing using FSL FEAT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "func_data_preproc=data_path + \"\\\\run-1.feat\\\\filtered_func_data.nii.gz\"\n",
    "\n",
    "mean_fmri_img=mean_img(func_data_preproc)\n",
    "plotting.plot_img(mean_fmri_img, cut_coords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "func_data_preproc_2high=data_path + \"\\\\run-1.feat\\\\reg\\\\example_func2standard.nii.gz\"\n",
    "\n",
    "mean_fmri_img_2high=mean_img(func_data_preproc_2high)\n",
    "\n",
    "print(image.load_img(func_data_preproc_2high).shape)\n",
    "\n",
    "plotting.plot_img(mean_fmri_img_2high, cut_coords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "func_data_preproc_2standard=data_path + \"\\\\run-1.feat\\\\filtered_func_data2standard.nii.gz\"\n",
    "\n",
    "mean_fmri_img_2standard=mean_img(func_data_preproc_2standard)\n",
    "\n",
    "print(image.load_img(func_data_preproc_2standard).shape)\n",
    "\n",
    "plotting.plot_img(mean_fmri_img_2standard, cut_coords)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Look at the events and design matrix."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nilearn.glm.first_level import make_first_level_design_matrix\n",
    "from nilearn.plotting import plot_design_matrix\n",
    "\n",
    "tr = 2.5  # repetition time is ? second\n",
    "n_scans = 222  # the acquisition comprises ?? scans\n",
    "frame_times = np.arange(n_scans) * tr  # here are the correspoding frame times\n",
    "\n",
    "# load events.tsv\n",
    "events_PATH=root_project+\"\\\\convert-bids-admin\\\\events.tsv\"\n",
    "\n",
    "events_df = pd.read_csv(events_PATH, sep='\\t', na_values=\"n/a\")\n",
    "print(events_df.head())\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hrf_model='spm'\n",
    "design_matrix = make_first_level_design_matrix(frame_times, events_df,\n",
    "                                    drift_model='polynomial', drift_order=3,\n",
    "                                    hrf_model=hrf_model)\n",
    "\n",
    "plot_design_matrix(design_matrix)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Statistical analysis - 1st level**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "contrast_matrix = np.eye(design_matrix.shape[1])\n",
    "basic_contrasts = dict([(column, contrast_matrix[i])\n",
    "                        for i, column in enumerate(design_matrix.columns)])\n",
    "basic_contrasts['+Task-Baseline'] = (\n",
    "    basic_contrasts['Task ']\n",
    "    - basic_contrasts['Baseline '])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "basic_contrasts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nilearn.glm.first_level import FirstLevelModel\n",
    "\n",
    "fmri_img=data_path + \"\\\\run-1.feat\\\\filtered_func_data2standard.nii.gz\"\n",
    "\n",
    "print('Fitting a GLM')\n",
    "fmri_glm = FirstLevelModel()\n",
    "fmri_glm = fmri_glm.fit(fmri_img, design_matrices=design_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nilearn.glm.first_level import run_glm\n",
    "labels, estimates = run_glm(texture.T, design_matrix.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_image = mean_img(fmri_img)\n",
    "contrast =compute_contrast(labels, estimates, basic_contrasts['+Task-Baseline'], contrast_type='t')\n",
    "z_map = fmri_glm.compute_contrast(basic_contrasts['+Task-Baseline'], output_type='z_score')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot the contrasts \n",
    "# the display is overlayed on the mean fMRI image\n",
    "# a threshold of 3.0 is used, more sophisticated choices are possible\n",
    "plotting.plot_stat_map(\n",
    "    z_map, bg_img=mean_image, threshold=3, display_mode='mosaic', black_bg=True, title='+Task-Baseline')\n",
    "plotting.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Project map in surface.\n",
    "\n",
    "fsaverage5 template from the FreeSurfer software."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fsaverage = nilearn.datasets.fetch_surf_fsaverage()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The projection function simply takes the fMRI data and the mesh. Note that those correspond spatially, are they are both in MNI space."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "texture = surface.vol_to_surf(fmri_img, fsaverage.pial_right)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we present the Z-transform of the t map\n",
    "z_map = contrast.z_score()\n",
    "z_map.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we plot it on the surface, on the inflated fsaverage mesh,\n",
    "# together with a suitable background to give an impression\n",
    "# of the cortex folding.\n",
    "plotting.plot_surf_stat_map(fsaverage.infl_left, z_map,\n",
    "                            hemi='left',title='l_lateral',\n",
    "                            colorbar=True,threshold=3.,\n",
    "                            bg_map=fsaverage.sulc_left)\n",
    "\n",
    "plotting.plot_surf_stat_map(fsaverage.infl_right, z_map,\n",
    "                            hemi='left',title='L_medial',\n",
    "                            colorbar=True,threshold=3.,\n",
    "                            bg_map=fsaverage.sulc_right)\n",
    "\n",
    "plotting.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Decoding \n",
    "\n",
    "## A first estimator.\n",
    "http://nilearn.github.io/decoding/decoding_intro.html#performing-a-simple-decoding-analysis\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nilearn.decoding import Decoder \n",
    "\n",
    "decoder = Decoder(estimator='svc') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# brain_mask = datasets.load_mni152_brain_mask()\n",
    "\n",
    "from nilearn.datasets import fetch_icbm152_brain_gm_mask\n",
    "brain_mask = fetch_icbm152_brain_gm_mask()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plotting.plot_roi(brain_mask, bg_img=t1w_prepro_file_path,\n",
    "                  cmap='Paired')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load the behavioral data. \n",
    "\n",
    "define the labels (classes) and the corresponding data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fmri_niiimgs=image.load_img(func_data_preproc_2standard)\n",
    "fmri_niiimgs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "decoder.fit(fmri_niiimgs, conditions) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
