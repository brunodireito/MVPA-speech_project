{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nilearn\n",
    "import sklearn\n",
    "from nilearn import plotting\n",
    "from nilearn import datasets\n",
    "from nilearn import image\n",
    "from nilearn.image import mean_img,math_img,index_img,concat_imgs\n",
    "from nilearn.glm.first_level import make_first_level_design_matrix\n",
    "from nilearn.plotting import plot_design_matrix\n",
    "from nilearn.input_data import NiftiMasker\n",
    "\n",
    "from sklearn.model_selection import KFold,train_test_split\n",
    "from nilearn.decoding import Decoder \n",
    "from sklearn import svm\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "import time\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set variables\n",
    "ROOT_DATA='/Users/home/Documents/BIDS/'\n",
    "#ROOT_DATA='/home/brunomiguel/Documents/data/BIDS/'\n",
    "SUB='sub-0001'\n",
    "SES='ses-001'\n",
    "TASK='innerspeech'\n",
    "RUN=['run-01','run-02','run-03']\n",
    "\n",
    "# project folder\n",
    "ROOT_PROJECT=\"/Volumes/LANGLYBACKU/MVPA_Speech_project\"\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# mask selection\n",
    "dataset = datasets.fetch_atlas_harvard_oxford('cort-maxprob-thr25-2mm') \n",
    "atlas_filename = dataset.maps\n",
    "\n",
    "area_idx=[47,48]\n",
    "area_idx=[4,5]\n",
    "mask = mean_img([math_img('img == %d'  %i, img=atlas_filename) for i in area_idx])\n",
    "plotting.plot_stat_map(mask)\n",
    "\n",
    "masker=NiftiMasker(mask_img=mask, standardize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bs_maps=None\n",
    "classification_target=None\n",
    "\n",
    "for r in RUN:\n",
    "    \n",
    "    # Load data\n",
    "    bs_fn=os.path.join(SUB + '_' + SES + '_task-' + TASK + '_'+ r +'_bold_bs.nii.gz')\n",
    "    bs_map= image.load_img(bs_fn)\n",
    "    \n",
    "    \n",
    "    # Mask data\n",
    "    # masker=NiftiMasker(mask_img=mask, standardize=True)\n",
    "    # mask_timecourse=masker.fit_transform(bs_maps)\n",
    "    \n",
    "    # Load labels\n",
    "    labels_fn=os.path.join(SUB + '_' + SES + '_task-' + TASK + '_'+ r +'_labels.csv')\n",
    "    col_list = [\"0\"]\n",
    "    labels=pd.read_csv(labels_fn, usecols=col_list)\n",
    "    \n",
    "    \n",
    "    if bs_maps is None:\n",
    "        bs_maps=bs_map\n",
    "        classification_target=labels\n",
    "    else:\n",
    "        bs_maps=[bs_maps,bs_map]\n",
    "        classification_target=np.vstack((classification_target, labels))\n",
    "    \n",
    "    del bs_map,labels\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "bs_maps=concat_imgs(bs_maps, auto_resample=True)\n",
    "print(bs_maps.shape)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(bs_maps, classification_target, test_size=0.2, random_state=10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_tags=['Baseline', 'Syllables', 'Words', 'Phrases', 'Vogals']\n",
    "\n",
    "# Then we define the various classifiers that we use\n",
    "classifiers = ['svc_l1']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Here we compute prediction scores and run time for all these\n",
    "# classifiers\n",
    "cv = 3\n",
    "classifiers_data = {}\n",
    "classifiers = ['svc_l1']\n",
    "\n",
    "for classifier_name in classifiers:\n",
    "    print(70 * '_')\n",
    "   \n",
    "    decoder = Decoder(estimator=classifier_name,mask=masker,\n",
    "                      standardize=True, cv=cv, scoring='accuracy')\n",
    "    \n",
    "    t0 = time.time()\n",
    "    decoder.fit(bs_maps, classification_target)\n",
    "\n",
    "    classifiers_data[classifier_name] = {}\n",
    "    classifiers_data[classifier_name]['score'] = decoder.cv_scores_\n",
    "\n",
    "    print(\"%10s: %.2fs\" % (classifier_name, time.time() - t0))\n",
    "    for target_tag in target_tags:\n",
    "        print(\"    %14s vs all -- ACC: %1.2f +- %1.2f\" % (\n",
    "            target_tag,\n",
    "            np.mean(classifiers_data[classifier_name]['score'][target_tag]),\n",
    "            np.std(classifiers_data[classifier_name]['score'][target_tag]))\n",
    "        )\n",
    "\n",
    "    # Adding the average performance per estimator\n",
    "    scores = classifiers_data[classifier_name]['score']\n",
    "    scores['AVERAGE'] = np.mean(list(scores.values()), axis=0)\n",
    "    classifiers_data[classifier_name]['score'] = scores\n",
    "    \n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "decoder.cv_scores_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('area_comparison.txt', 'a+') as f:\n",
    "    print(area_idx,file=f)\n",
    "    print(classifiers_data,file=f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Comparison with Dummy predictor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.dummy import DummyClassifier\n",
    "# Here we compute prediction scores and run time for all these\n",
    "# classifiers\n",
    "import time\n",
    "\n",
    "cv = 5\n",
    "classifiers_data = {}\n",
    "classifiers=['dummy']\n",
    "\n",
    "for classifier_name in classifiers:\n",
    "    print(70 * '_')\n",
    "\n",
    "    # The decoder has as default score the `roc_auc`\n",
    "    decoder = Decoder(estimator=DummyClassifier(strategy='stratified'),mask=masker,cv=cv,\n",
    "                      standardize=True, scoring='accuracy')\n",
    " \n",
    "    t0 = time.time()\n",
    "    decoder.fit(bs_maps, classification_target)\n",
    "\n",
    "    classifiers_data[classifier_name] = {}\n",
    "    classifiers_data[classifier_name]['score'] = decoder.cv_scores_\n",
    "\n",
    "    print(\"%10s: %.2fs\" % (classifier_name, time.time() - t0))\n",
    "    for target_tag in target_tags:\n",
    "        print(\"    %14s vs all -- ACC: %1.2f +- %1.2f\" % (\n",
    "            target_tag,\n",
    "            np.mean(classifiers_data[classifier_name]['score'][target_tag]),\n",
    "            np.std(classifiers_data[classifier_name]['score'][target_tag]))\n",
    "        )\n",
    "\n",
    "    # Adding the average performance per estimator\n",
    "    scores = classifiers_data[classifier_name]['score']\n",
    "    scores['AVERAGE'] = np.mean(list(scores.values()), axis=0)\n",
    "    classifiers_data[classifier_name]['score'] = scores\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mask_timecourse=masker.fit_transform(bs_maps)\n",
    "null_cv_scores = cross_val_score(\n",
    "    DummyClassifier(strategy='prior'),mask_timecourse, classification_target, scoring='accuracy')\n",
    "print(null_cv_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dummy_clf = DummyClassifier()\n",
    "dummy_clf.fit(mask_timecourse, classification_target)\n",
    "\n",
    "dummy_clf.score(mask_timecourse, classification_target)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Playing with other masks\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nilearn.datasets import fetch_icbm152_brain_gm_mask\n",
    "brain_mask = fetch_icbm152_brain_gm_mask()\n",
    "\n",
    "\n",
    "# Then we define the various classifiers that we use\n",
    "classifiers = ['svc_l1','logistic_l1']\n",
    "\n",
    "\n",
    "# Here we compute prediction scores and run time for all these\n",
    "# classifiers\n",
    "import time\n",
    "\n",
    "cv = 5\n",
    "classifiers_data = {}\n",
    "\n",
    "for classifier_name in classifiers:\n",
    "    print(70 * '_')\n",
    "\n",
    "    # The decoder has as default score the `roc_auc`\n",
    "    decoder = Decoder(estimator=classifier_name,mask=brain_mask,\n",
    "                      standardize=True, cv=cv, scoring='accuracy')\n",
    "    t0 = time.time()\n",
    "    decoder.fit(bs_maps, classification_target)\n",
    "\n",
    "    classifiers_data[classifier_name] = {}\n",
    "    classifiers_data[classifier_name]['score'] = decoder.cv_scores_\n",
    "\n",
    "    print(\"%10s: %.2fs\" % (classifier_name, time.time() - t0))\n",
    "    for target_tag in target_tags:\n",
    "        print(\"    %14s vs all -- AUC: %1.2f +- %1.2f\" % (\n",
    "            target_tag,\n",
    "            np.mean(classifiers_data[classifier_name]['score'][target_tag]),\n",
    "            np.std(classifiers_data[classifier_name]['score'][target_tag]))\n",
    "        )\n",
    "\n",
    "    # Adding the average performance per estimator\n",
    "    scores = classifiers_data[classifier_name]['score']\n",
    "    scores['AVERAGE'] = np.mean(list(scores.values()), axis=0)\n",
    "    classifiers_data[classifier_name]['score'] = scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
