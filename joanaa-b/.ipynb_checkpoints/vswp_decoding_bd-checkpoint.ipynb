{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nilearn\n",
    "from nilearn import plotting\n",
    "from nilearn import datasets\n",
    "from nilearn import image\n",
    "from nilearn.image import mean_img\n",
    "from nilearn.image import index_img\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Averiguação da shape do dataset e importação do mesmo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "# Set variables\n",
    "ROOT_DATA='/Users/home/Documents/BIDS/'\n",
    "#ROOT_DATA='/home/brunomiguel/Documents/data/BIDS/'\n",
    "SUB='sub-0001'\n",
    "SES='ses-001'\n",
    "TASK='innerspeech'\n",
    "RUN='run-02'\n",
    "\n",
    "\n",
    "# data folder\n",
    "data_path=os.path.join(ROOT_DATA, SUB, SES)\n",
    "print('The data is in this folder - ' + data_path)\n",
    "\n",
    "# project folder\n",
    "ROOT_PROJECT=\"/Users/home/Documents/GitHub/MVPA-speech_project\"\n",
    "\n",
    "\n",
    "fmri_img=os.path.join(data_path, 'func', \n",
    "                          SUB + '_' + SES + '_task-' + TASK + '_'+ RUN +'_bold_pp_standard.nii.gz')\n",
    "dataset_shape=(image.load_img(fmri_img).shape)\n",
    "\n",
    "print(dataset_shape)\n",
    "dataset_shape[3]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Eventos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nilearn.glm.first_level import make_first_level_design_matrix\n",
    "from nilearn.plotting import plot_design_matrix\n",
    "\n",
    "tr = 2  # repetition time is ? second\n",
    "n_scans = dataset_shape[3]  # the acquisition comprises ?? scans\n",
    "frame_times = np.arange(n_scans) * tr  # here are the correspoding frame times\n",
    "\n",
    "# load events.tsv\n",
    "events_PATH=os.path.join(data_path, 'func', \n",
    "                          SUB + '_' + SES + \n",
    "                          '_task-' + TASK + '_'+ RUN + '_events.tsv')\n",
    "\n",
    "events_df = pd.read_csv(events_PATH, sep='\\t', na_values=\"n/a\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Criação da tabela design_matrix (por fases e não betas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hrf_model='spm'\n",
    "design_matrix = make_first_level_design_matrix(frame_times, events_df,\n",
    "                                    drift_model='polynomial', drift_order=3,\n",
    "                                    hrf_model=hrf_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nilearn.glm.first_level import FirstLevelModel\n",
    "\n",
    "first_level_model = FirstLevelModel(tr)\n",
    "first_level_model = first_level_model.fit(fmri_img, events=events_df)\n",
    "design_matrix = first_level_model.design_matrices_[0]\n",
    "plot_design_matrix(design_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "contrast_matrix = np.eye(design_matrix.shape[1])\n",
    "basic_contrasts = dict([(column, contrast_matrix[i])\n",
    "                        for i, column in enumerate(design_matrix.columns)])\n",
    "basic_contrasts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fmri_glm4mask = FirstLevelModel()\n",
    "fmri_glm4mask = fmri_glm4mask.fit(fmri_img, design_matrices=design_matrix)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Beta-series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "onset=[]\n",
    "duration=[]\n",
    "trialtype=[]\n",
    "\n",
    "labels=[]\n",
    "\n",
    "onsett=0\n",
    "evtt=0\n",
    "\n",
    "for idx in range(len(events_df)-1):\n",
    "    block_event=events_df.loc[idx]\n",
    "\n",
    "    num_evts=block_event['duration']/tr\n",
    "\n",
    "    for evt in range(int(num_evts)):\n",
    "\n",
    "        onset.append(onsett)\n",
    "        onsett+=tr\n",
    "\n",
    "        duration.append(tr)\n",
    "\n",
    "        trialtype.append(evtt)\n",
    "        evtt+=1\n",
    "\n",
    "        labels.append(block_event['trial_type'])\n",
    "\n",
    "\n",
    "events_bs = pd.DataFrame({'trial_type': trialtype,\n",
    "                       'onset': onset,\n",
    "                       'duration': duration})\n",
    "events_bs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.DataFrame(labels)\n",
    "\n",
    "labels_fn=os.path.join(SUB + '_' + SES + '_task-' + TASK + '_'+ RUN +'_labels.csv')\n",
    "\n",
    "df.to_csv(labels_fn)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "first_level_model = FirstLevelModel(tr)\n",
    "first_level_model = first_level_model.fit(fmri_img, events=events_bs)\n",
    "design_matrix_b_series = first_level_model.design_matrices_[0]\n",
    "plot_design_matrix(design_matrix_b_series)\n",
    "design_matrix_b_series.drop({'drift_1', 'drift_2', 'drift_3', 'drift_4', 'drift_5', 'drift_6', 'drift_7', 'drift_8', 'drift_9', 'drift_10', 'constant'}, axis='columns', inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Contrastes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "contrast_matrix_b_series = np.eye(design_matrix_b_series.shape[1])\n",
    "basic_contrasts_b_series = dict([(column, contrast_matrix_b_series[i]) for i, column in enumerate(design_matrix_b_series.columns)])\n",
    "    \n",
    "\n",
    "fmri_glm = FirstLevelModel()\n",
    "fmri_glm = fmri_glm.fit(fmri_img, design_matrices=design_matrix_b_series)\n",
    "\n",
    "mean_image = mean_img(fmri_img)\n",
    "z_map=[]\n",
    "\n",
    "for idx in range(len(basic_contrasts_b_series)):\n",
    "    z_map.append(fmri_glm.compute_contrast(basic_contrasts_b_series[idx], output_type='z_score'))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "contrast_matrix_b_series.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(basic_contrasts_b_series)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Teste de imagem\n",
    "plotting.plot_stat_map(\n",
    "    z_map[1], bg_img=mean_image, threshold=2, display_mode='mosaic', black_bg=True, title='test')\n",
    "plotting.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#bs_fn=os.path.join(data_path, 'func', SUB + '_' + SES + '_task-' + TASK + '_'+ RUN +'_bold_bs.nii.gz')\n",
    "import nibabel as nib\n",
    "\n",
    "bs_fn=os.path.join( SUB + '_' + SES + '_task-' + TASK + '_'+ RUN +'_bold_bs.nii.gz')\n",
    "\n",
    "img4D=nilearn.image.concat_imgs(z_map)\n",
    "img4D.to_filename(bs_fn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## As linhas abaixo será para criação de máscaras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#contraste entre frases e baseline\n",
    "basic_contrasts['+Phrases-Baseline'] = (\n",
    "    basic_contrasts['Phrases']\n",
    "    - basic_contrasts['Baseline'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nilearn.input_data import NiftiMasker\n",
    "\n",
    "masker = NiftiMasker()\n",
    "\n",
    "brain_mask_map = fmri_glm4mask.compute_contrast(basic_contrasts['+Phrases-Baseline'], output_type='z_score')\n",
    "\n",
    "brain_mask= nilearn.image.threshold_img(brain_mask_map, threshold=8, copy=False)\n",
    "masker.fit(brain_mask)\n",
    "brain_mask=masker.mask_img_\n",
    "plotting.plot_roi(brain_mask, bg_img=mean_image,\n",
    "                  cmap='Paired')\n",
    "\n",
    "mask_fn=os.path.join( SUB + '_' + SES + '_task-' + TASK + '_'+ RUN +'_mask.nii.gz')\n",
    "brain_mask.to_filename(mask_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# debug\n",
    "brain_mask_map= nilearn.image.load_img(mask_fn)\n",
    "\n",
    "plotting.plot_roi(brain_mask, bg_img=mean_image,\n",
    "                  cmap='Paired')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importação da brain_mask (caso se queira usar gm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "brain_mask = datasets.load_mni152_brain_mask()\n",
    "\n",
    "from nilearn.datasets import fetch_icbm152_brain_gm_mask\n",
    "brain_mask = fetch_icbm152_brain_gm_mask()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cross-validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "from nilearn.decoding import Decoder \n",
    "\n",
    "cv = KFold(n_splits=3)\n",
    "\n",
    "fold = 0\n",
    "for train, test in cv.split(labels):\n",
    "    fold += 1\n",
    "    decoder = Decoder(estimator='svc', mask=brain_mask, standardize=True)\n",
    "    decoder.fit(index_img(z_map, train), [labels[i] for i in train])\n",
    "    prediction = decoder.predict(index_img(z_map, test))\n",
    "    print(\n",
    "        \"CV Fold {:01d} | Prediction Accuracy: {:.3f}\".format(\n",
    "            fold,\n",
    "            (prediction == [labels[i] for i in test]).sum() / float(len(\n",
    "                test))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.unique(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "decoder = Decoder(estimator='svc',cv=3, mask=brain_mask, standardize=True)\n",
    "decoder.fit(z_map, labels)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv_scores=[]\n",
    "for i, (param, cv_score) in enumerate(zip(decoder.cv_params_,\n",
    "                                          decoder.cv_scores_)):\n",
    "\n",
    "    print(i)\n",
    "    print(decoder.cv_scores_)\n",
    "    cv_scores=np.mean(decoder.cv_scores_['Phrases'])\n",
    "    \n",
    "    with open('results.txt', 'a+') as f:\n",
    "        print(\"Fold %d | score: %.3f\" % (i + 1, cv_scores),file=f)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "decoder.cv_scores_\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
